{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-25 12:42:23.697122: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-25 12:42:23.697206: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-25 12:42:23.777699: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-25 12:42:23.971258: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-25 12:42:25.519183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-25 12:42:27.675738: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-25 12:42:27.946379: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-25 12:42:27.946686: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-25 12:42:27.950758: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-25 12:42:27.951346: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-25 12:42:27.951773: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-25 12:42:28.315720: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-25 12:42:28.316199: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-25 12:42:28.316217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-25 12:42:28.316564: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-25 12:42:28.316605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5595 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to multiply two matrices on CPU: 7.546968698501587 seconds\n",
      "Time taken to multiply two matrices on GPU: 0.3188819885253906 seconds\n",
      "Speedup from GPU over CPU: 23.666964488653356x\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Function to perform matrix multiplication on a specific device\n",
    "def perform_matrix_multiplication(device_name):\n",
    "    with tf.device(device_name):\n",
    "        # Random matrices of size 10000x10000\n",
    "        a = tf.random.normal([10000, 10000])\n",
    "        b = tf.random.normal([10000, 10000])\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Performing matrix multiplication\n",
    "        c = tf.matmul(a, b)\n",
    "        # Ensure the computation is complete with `tf.compat.v1.Session.run` or `tf.reduce_sum`\n",
    "        tf.reduce_sum(c)  # This forces the execution of the multiplication\n",
    "        end_time = time.time()\n",
    "\n",
    "    return end_time - start_time  # Return the time taken for the operation\n",
    "\n",
    "# Run matrix multiplication on CPU\n",
    "cpu_time = perform_matrix_multiplication('/CPU:0')\n",
    "print(f\"Time taken to multiply two matrices on CPU: {cpu_time} seconds\")\n",
    "\n",
    "# If a GPU is available, run the matrix multiplication on GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu_time = perform_matrix_multiplication('/GPU:0')\n",
    "    print(f\"Time taken to multiply two matrices on GPU: {gpu_time} seconds\")\n",
    "    print(f\"Speedup from GPU over CPU: {cpu_time/gpu_time}x\")\n",
    "else:\n",
    "    print(\"No GPU found. Please install TensorFlow with GPU support and ensure you have a compatible GPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-25.21171   -15.00795   -47.54557   ...  26.132715   47.410583\n",
      "   -5.137459 ]\n",
      " [ 32.976593   31.447002   26.435207  ... -27.413687   -7.8577833\n",
      "  -15.869736 ]\n",
      " [  7.272471  -35.530746   -6.715096  ...  30.648771   13.504829\n",
      "   42.0355   ]\n",
      " ...\n",
      " [-11.756889  -32.35502    30.381445  ...  43.966766  -40.25678\n",
      "  -14.970104 ]\n",
      " [-12.614656   18.945028  -10.417493  ...   6.8377333   2.1021197\n",
      "  -36.534637 ]\n",
      " [-27.715652   -1.5450845 -28.627815  ... -35.166393   13.873825\n",
      "   -8.943923 ]]\n",
      "Time taken for matrix multiplication on GPU: 0.9891977310180664 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "b = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    c = tf.matmul(a, b)\n",
    "    print(c.numpy())  # This will force the execution of the GPU operation\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "# Calculate and print the time taken\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken for matrix multiplication on GPU: {time_taken} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 54.706417    35.25223    -25.931446   ... -32.786674     0.3133008\n",
      "   37.327927  ]\n",
      " [ 62.154137    38.426796    23.918774   ...  18.37424     28.097923\n",
      "  -17.517694  ]\n",
      " [ -1.1632054   35.89683    -33.764175   ...  23.45009     -8.651368\n",
      "   50.360504  ]\n",
      " ...\n",
      " [-21.110142     0.29014564  26.03484    ...   5.524087    17.23555\n",
      "   17.679863  ]\n",
      " [-20.70401    -16.110723    30.068432   ... -17.256062   -23.555487\n",
      "  -46.928604  ]\n",
      " [ -2.6144938  -50.252144     9.069513   ...  19.887709   -20.926338\n",
      "   24.30942   ]]\n",
      "Time taken for matrix multiplication on CPU: 8.297615051269531 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "b = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    c = tf.matmul(a, b)\n",
    "    print(c.numpy())  # This will force the execution of the GPU operation\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "# Calculate and print the time taken\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken for matrix multiplication on CPU: {time_taken} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
