{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 22:27:38.030537: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-20 22:27:38.030680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-20 22:27:38.037224: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-20 22:27:38.070282: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 22:27:39.058344: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-20 22:27:39.934425: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-20 22:27:40.010855: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-20 22:27:40.011177: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-20 22:27:40.014185: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-20 22:27:40.014520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-20 22:27:40.014772: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-20 22:27:40.167378: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-20 22:27:40.167683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-20 22:27:40.167696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-20 22:27:40.167928: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-20 22:27:40.167957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5595 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-12-20 22:27:40.190427: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2023-12-20 22:27:40.368465: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2023-12-20 22:27:40.493910: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2023-12-20 22:27:40.678022: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2023-12-20 22:27:40.879307: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to multiply two matrices on CPU: 7.52169942855835 seconds\n",
      "Time taken to multiply two matrices on GPU: 0.2878265380859375 seconds\n",
      "Speedup from GPU over CPU: 26.132751616922018x\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Function to perform matrix multiplication on a specific device\n",
    "def perform_matrix_multiplication(device_name):\n",
    "    with tf.device(device_name):\n",
    "        # Random matrices of size 10000x10000\n",
    "        a = tf.random.normal([10000, 10000])\n",
    "        b = tf.random.normal([10000, 10000])\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Performing matrix multiplication\n",
    "        c = tf.matmul(a, b)\n",
    "        # Ensure the computation is complete with `tf.compat.v1.Session.run` or `tf.reduce_sum`\n",
    "        tf.reduce_sum(c)  # This forces the execution of the multiplication\n",
    "        end_time = time.time()\n",
    "\n",
    "    return end_time - start_time  # Return the time taken for the operation\n",
    "\n",
    "# Run matrix multiplication on CPU\n",
    "cpu_time = perform_matrix_multiplication('/CPU:0')\n",
    "print(f\"Time taken to multiply two matrices on CPU: {cpu_time} seconds\")\n",
    "\n",
    "# If a GPU is available, run the matrix multiplication on GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu_time = perform_matrix_multiplication('/GPU:0')\n",
    "    print(f\"Time taken to multiply two matrices on GPU: {gpu_time} seconds\")\n",
    "    print(f\"Speedup from GPU over CPU: {cpu_time/gpu_time}x\")\n",
    "else:\n",
    "    print(\"No GPU found. Please install TensorFlow with GPU support and ensure you have a compatible GPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20.826351  -10.377904   19.144958  ...   9.106541  -35.388725\n",
      "  -23.901659 ]\n",
      " [ 27.77131     2.2206004   7.8245883 ... -52.72453    17.865572\n",
      "  -33.91282  ]\n",
      " [ 34.936424    3.9214725  12.059947  ... -11.826799  -22.960577\n",
      "   10.02722  ]\n",
      " ...\n",
      " [-13.130393  116.99628   -30.282137  ... 104.0798    -25.496578\n",
      "  -90.80625  ]\n",
      " [-14.896624   44.218502   34.597813  ...  17.772146  -19.295525\n",
      "  -38.384884 ]\n",
      " [  5.3490667  37.013767    9.868298  ...  31.596693   64.08423\n",
      "   89.68532  ]]\n",
      "Time taken for matrix multiplication on GPU: 1.547560691833496 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "b = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    c = tf.matmul(a, b)\n",
    "    print(c.numpy())  # This will force the execution of the GPU operation\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "# Calculate and print the time taken\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken for matrix multiplication on GPU: {time_taken} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-22.050137    27.594654   -33.4969     ...  29.05776    -59.836163\n",
      "   20.963581  ]\n",
      " [-18.175238    30.86615     40.996117   ...  22.481152    20.784237\n",
      "   55.723404  ]\n",
      " [ 24.028183     0.31725502 -33.73317    ...  14.069219   -47.05213\n",
      "   14.342605  ]\n",
      " ...\n",
      " [ -5.3877506    1.2093189   23.639315   ...  32.074562   -63.377113\n",
      "   60.591873  ]\n",
      " [ 56.366985    51.459557    -6.1103654  ... -43.658554    24.827822\n",
      "  -16.892273  ]\n",
      " [-39.8752      -5.703271    39.06949    ... -17.966967   -44.217667\n",
      "   13.454746  ]]\n",
      "Time taken for matrix multiplication on CPU: 9.173386573791504 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "b = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    c = tf.matmul(a, b)\n",
    "    print(c.numpy())  # This will force the execution of the GPU operation\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "# Calculate and print the time taken\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken for matrix multiplication on CPU: {time_taken} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
