{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 14:04:41.338547: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-23 14:04:41.338659: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-23 14:04:41.343326: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-23 14:04:41.368691: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 14:04:42.413144: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Using TensorFlow backend.\n",
      "2024-01-23 14:04:43.172087: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 14:04:43.415271: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 14:04:43.415642: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 14:04:43.420744: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 14:04:43.421342: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 14:04:43.421659: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 14:04:43.814921: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 14:04:43.815258: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 14:04:43.815271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-01-23 14:04:43.815571: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 14:04:43.816074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5595 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-01-23 14:04:43.859765: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2024-01-23 14:04:44.238580: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2024-01-23 14:04:45.542402: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2024-01-23 14:04:46.697016: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2024-01-23 14:04:46.921460: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 400000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to multiply two matrices on CPU: 6.402997970581055 seconds\n",
      "Time taken to multiply two matrices on GPU: 0.38198328018188477 seconds\n",
      "Speedup from GPU over CPU: 16.762508472968268x\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Function to perform matrix multiplication on a specific device\n",
    "def perform_matrix_multiplication(device_name):\n",
    "    with tf.device(device_name):\n",
    "        # Random matrices of size 10000x10000\n",
    "        a = tf.random.normal([10000, 10000])\n",
    "        b = tf.random.normal([10000, 10000])\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Performing matrix multiplication\n",
    "        c = tf.matmul(a, b)\n",
    "        # Ensure the computation is complete with `tf.compat.v1.Session.run` or `tf.reduce_sum`\n",
    "        tf.reduce_sum(c)  # This forces the execution of the multiplication\n",
    "        end_time = time.time()\n",
    "\n",
    "    return end_time - start_time  # Return the time taken for the operation\n",
    "\n",
    "# Run matrix multiplication on CPU\n",
    "cpu_time = perform_matrix_multiplication('/CPU:0')\n",
    "print(f\"Time taken to multiply two matrices on CPU: {cpu_time} seconds\")\n",
    "\n",
    "# If a GPU is available, run the matrix multiplication on GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu_time = perform_matrix_multiplication('/GPU:0')\n",
    "    print(f\"Time taken to multiply two matrices on GPU: {gpu_time} seconds\")\n",
    "    print(f\"Speedup from GPU over CPU: {cpu_time/gpu_time}x\")\n",
    "else:\n",
    "    print(\"No GPU found. Please install TensorFlow with GPU support and ensure you have a compatible GPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-14.545351   -8.4889555 -60.110455  ... -40.944645  -34.670364\n",
      "   62.84945  ]\n",
      " [-68.11143    17.680082   18.15697   ... -89.60402   -20.52902\n",
      "  -16.99297  ]\n",
      " [ 14.312053   -0.3597568 -17.217241  ... -22.93577    52.079205\n",
      "  -27.184227 ]\n",
      " ...\n",
      " [-18.739649   41.941456  -53.37399   ...  14.92759    14.136693\n",
      "  -52.71522  ]\n",
      " [ -4.0409403   4.7875357  24.028845  ... -26.043665   39.84747\n",
      "  -11.286449 ]\n",
      " [-37.444393  -32.237522  -39.91924   ...  78.06509     8.537607\n",
      "   26.353275 ]]\n",
      "Time taken for matrix multiplication on GPU: 0.9467875957489014 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "b = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    c = tf.matmul(a, b)\n",
    "    print(c.numpy())  # This will force the execution of the GPU operation\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "# Calculate and print the time taken\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken for matrix multiplication on GPU: {time_taken} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 36.38397     44.90375     49.45376    ...  12.0459795  -29.14992\n",
      "  -37.838264  ]\n",
      " [  1.2421317  -23.204851     3.2676783  ... -30.352898    27.898645\n",
      "   81.74854   ]\n",
      " [  6.0347133   46.271523    40.050983   ...   2.8019614   -7.239757\n",
      "  -56.143826  ]\n",
      " ...\n",
      " [ -7.089134   -29.006289    -1.4132609  ...  13.309383     0.6615084\n",
      "  -12.87498   ]\n",
      " [ 56.52037     -9.148498     0.15679961 ...  33.18579      5.339763\n",
      "    2.7371085 ]\n",
      " [-36.847916    62.344467    51.394547   ... -24.452961   -10.236273\n",
      "  -11.436697  ]]\n",
      "Time taken for matrix multiplication on CPU: 6.767409563064575 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "b = tf.random.uniform([10000, 10000], minval=-1, maxval=1)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    c = tf.matmul(a, b)\n",
    "    print(c.numpy())  # This will force the execution of the GPU operation\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "# Calculate and print the time taken\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken for matrix multiplication on CPU: {time_taken} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; \n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
